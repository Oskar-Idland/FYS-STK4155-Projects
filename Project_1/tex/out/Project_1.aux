\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{gasoline}
\citation{notes}
\newlabel{FirstPage}{{}{1}{}{section*.1}{}}
\newlabel{FirstPage@cref}{{}{[1][1][]1}}
\@writefile{toc}{\contentsline {title}{\begin{Large}Project 1\end{Large}\\\vspace  {5pt}FYS-STK4155}{1}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {abstract}{Abstract}{1}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section*.3}\protected@file@percent }
\newlabel{sec:introduction}{{I}{1}{}{section*.3}{}}
\newlabel{sec:introduction@cref}{{[section][1][]I}{[1][1][]1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Theory}{1}{section*.4}\protected@file@percent }
\newlabel{sec:theory}{{II}{1}{}{section*.4}{}}
\newlabel{sec:theory@cref}{{[section][2][]II}{[1][1][]1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Regression Analysis}{1}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1}Ordinary Least Squares}{2}{section*.6}\protected@file@percent }
\newlabel{subsubsec:ols}{{II\,A\,1}{2}{}{section*.6}{}}
\newlabel{subsubsec:ols@cref}{{[subsubsection][1][2,1]II\,A\,1}{[1][2][]2}}
\newlabel{eq:OLS cost}{{5}{2}{}{equation.2.5}{}}
\newlabel{eq:OLS cost@cref}{{[equation][5][]5}{[1][2][]2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2}Ridge}{2}{section*.7}\protected@file@percent }
\newlabel{subsubsec:ridge}{{II\,A\,2}{2}{}{section*.7}{}}
\newlabel{subsubsec:ridge@cref}{{[subsubsection][2][2,1]II\,A\,2}{[1][2][]2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3}Lasso}{3}{section*.8}\protected@file@percent }
\newlabel{subsubsec:lasso}{{II\,A\,3}{3}{}{section*.8}{}}
\newlabel{subsubsec:lasso@cref}{{[subsubsection][3][2,1]II\,A\,3}{[1][3][]3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B}Properties of Predictive Models}{3}{section*.9}\protected@file@percent }
\newlabel{subsec:tradeoff}{{II\,B}{3}{}{section*.9}{}}
\newlabel{subsec:tradeoff@cref}{{[subsection][2][2]II\,B}{[1][3][]3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1}Predicted Values}{3}{section*.10}\protected@file@percent }
\newlabel{eq:Bias}{{16}{3}{}{equation.2.16}{}}
\newlabel{eq:Bias@cref}{{[equation][16][]16}{[1][3][]3}}
\newlabel{eq:Var}{{17}{3}{}{equation.2.17}{}}
\newlabel{eq:Var@cref}{{[equation][17][]17}{[1][3][]3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2}Model Bias}{3}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3}Model Variance}{3}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4}Bias-Variance Tradeoff}{4}{section*.13}\protected@file@percent }
\newlabel{eq:MSE}{{18}{4}{}{equation.2.18}{}}
\newlabel{eq:MSE@cref}{{[equation][18][]18}{[1][4][]4}}
\newlabel{eq:R2}{{19}{4}{}{equation.2.19}{}}
\newlabel{eq:R2@cref}{{[equation][19][]19}{[1][4][]4}}
\newlabel{eq:model error}{{20}{4}{}{equation.2.20}{}}
\newlabel{eq:model error@cref}{{[equation][20][]20}{[1][4][]4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C}Resampling Methods}{4}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1}Bootstrap}{4}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2}Cross-Validation}{4}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {D}The Franke Function}{4}{section*.17}\protected@file@percent }
\newlabel{subsec:franke}{{II\,D}{4}{}{section*.17}{}}
\newlabel{subsec:franke@cref}{{[subsection][4][2]II\,D}{[1][4][]4}}
\citation{gasoline}
\citation{music}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Visualization of the two-dimensional Franke function expressed in \eqref  {eq:Franke}.}}{5}{figure.caption.23}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:Franke}{{1}{5}{Visualization of the two-dimensional Franke function expressed in \eqref {eq:Franke}}{figure.caption.23}{}}
\newlabel{fig:Franke@cref}{{[figure][1][]1}{[1][5][]5}}
\newlabel{eq:Franke}{{{21}}{5}{}{AMS.19}{}}
\newlabel{eq:Franke@cref}{{[equation][2147483647][]{21}}{[1][4][]5}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Methods \& Implementation}{5}{section*.20}\protected@file@percent }
\newlabel{sec:methods}{{III}{5}{}{section*.20}{}}
\newlabel{sec:methods@cref}{{[section][3][]III}{[1][5][]5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Generating the Data}{5}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1}Synthetic Data}{5}{section*.22}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2}Cosmological Simulation Data}{5}{section*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {B}Regression Analysis}{5}{section*.26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1}Creating the Design Matrix}{5}{section*.27}\protected@file@percent }
\citation{scikit-learn}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Logarithm of dark matter density in the simulation box averaged over one of the three axes at redshift $z\approx 12.88$. Plotted as contour plot on the left and as surface plot on the right. Because the Universe expands as time goes on the box does as well, and we therefore scale the coordinates of the box by multiplying with $a$. Similarly, space between the dark matter particles also increases with time, which is why the density is scaled by multiplying with $a^{-3}$. G\begin{footnotesize}ASOLINE\end{footnotesize}2 uses the rest of the scaling factors by default.}}{6}{figure.caption.25}\protected@file@percent }
\newlabel{fig:density}{{2}{6}{Logarithm of dark matter density in the simulation box averaged over one of the three axes at redshift $z\approx 12.88$. Plotted as contour plot on the left and as surface plot on the right. Because the Universe expands as time goes on the box does as well, and we therefore scale the coordinates of the box by multiplying with $a$. Similarly, space between the dark matter particles also increases with time, which is why the density is scaled by multiplying with $a^{-3}$. G\begin {footnotesize}ASOLINE\end {footnotesize}2 uses the rest of the scaling factors by default}{figure.caption.25}{}}
\newlabel{fig:density@cref}{{[figure][2][]2}{[1][5][]6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2}Preprocessing}{6}{section*.28}\protected@file@percent }
\citation{ESL}
\citation{ESL}
\citation{ESL}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3}Exploring Complexity Dependency Using OLS}{7}{section*.29}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4}Introducing Regularization}{7}{section*.30}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Illustration of bias-variance trade-off as a function of model complexity, taken from fig. 2.11 in Hastie, Tibshirani, and Friedman \cite  {ESL}}}{7}{figure.caption.32}\protected@file@percent }
\newlabel{fig:Hastie}{{3}{7}{Illustration of bias-variance trade-off as a function of model complexity, taken from fig. 2.11 in Hastie, Tibshirani, and Friedman \cite {ESL}}{figure.caption.32}{}}
\newlabel{fig:Hastie@cref}{{[figure][3][]3}{[1][7][]7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C}Bias-Variance Tradeoff}{7}{section*.31}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1}Bootstrap With OLS}{7}{section*.33}\protected@file@percent }
\citation{Python}
\citation{scikit-learn}
\citation{Numpy}
\citation{Matplotlib}
\citation{VSCode}
\citation{Copilot}
\citation{Git}
\citation{GitHub}
\@writefile{toc}{\contentsline {subsection}{\numberline {D}Cross-Validation}{8}{section*.34}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {E}The Program}{8}{section*.35}\protected@file@percent }
\newlabel{subsec:program}{{III\,E}{8}{}{section*.35}{}}
\newlabel{subsec:program@cref}{{[subsection][5][3]III\,E}{[1][8][]8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1}Code Structure}{8}{section*.36}\protected@file@percent }
\newlabel{subsubsec:codestructure}{{III\,E\,1}{8}{}{section*.36}{}}
\newlabel{subsubsec:codestructure@cref}{{[subsubsection][1][3,5]III\,E\,1}{[1][8][]8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2}Tools}{8}{section*.37}\protected@file@percent }
\newlabel{subsubsec:tools}{{III\,E\,2}{8}{}{section*.37}{}}
\newlabel{subsubsec:tools@cref}{{[subsubsection][2][3,5]III\,E\,2}{[1][8][]8}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Results \& Discussion}{8}{section*.38}\protected@file@percent }
\newlabel{sec:results discussion}{{IV}{8}{}{section*.38}{}}
\newlabel{sec:results discussion@cref}{{[section][4][]IV}{[1][8][]8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Effects of Data Scaling}{8}{section*.39}\protected@file@percent }
\newlabel{subsec:scaling effect}{{IV\,A}{8}{}{section*.39}{}}
\newlabel{subsec:scaling effect@cref}{{[subsection][1][4]IV\,A}{[1][8][]8}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces MSE (upper rows) and $R^2$ (lower rows) evaluated on the Franke function test set (upper section) and the cosmological simulation test set (lower section) using unscaled (left column) and scaled (right column) values. For the Franke function we have used polynomial degrees in the interval $[1,6]$, while for the cosmological data we have used every other degree in the interval $[1,41]$.}}{9}{figure.caption.40}\protected@file@percent }
\newlabel{fig:error scaled vs raw}{{4}{9}{MSE (upper rows) and $R^2$ (lower rows) evaluated on the Franke function test set (upper section) and the cosmological simulation test set (lower section) using unscaled (left column) and scaled (right column) values. For the Franke function we have used polynomial degrees in the interval $[1,6]$, while for the cosmological data we have used every other degree in the interval $[1,41]$}{figure.caption.40}{}}
\newlabel{fig:error scaled vs raw@cref}{{[figure][4][]4}{[1][8][]9}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The coefficients $\beta $ for the Franke (top) and cosmological (bottom) fits estimated using unscaled and scaled data, plotted for polynomial degrees in the intervals $[1,6]$ and $[1,41]$ for Franke and dark matter, respectively. We have used a logarithmic scale for the $\beta $'s in the latter case.}}{10}{figure.caption.41}\protected@file@percent }
\newlabel{fig:beta scaled vs raw}{{5}{10}{The coefficients $\beta $ for the Franke (top) and cosmological (bottom) fits estimated using unscaled and scaled data, plotted for polynomial degrees in the intervals $[1,6]$ and $[1,41]$ for Franke and dark matter, respectively. We have used a logarithmic scale for the $\beta $'s in the latter case}{figure.caption.41}{}}
\newlabel{fig:beta scaled vs raw@cref}{{[figure][5][]5}{[1][9][]10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B}Hyperparameter Dependency}{10}{section*.42}\protected@file@percent }
\newlabel{subsec:hyperparameter}{{IV\,B}{10}{}{section*.42}{}}
\newlabel{subsec:hyperparameter@cref}{{[subsection][2][4]IV\,B}{[1][10][]10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C}Bias-Variance Tradeoff}{10}{section*.44}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1}Training and Test Errors}{10}{section*.45}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces MSE (upper rows) and $R^2$ (lower rows) for Ridge (top section) and Lasso (bottom section) regression evaluated on the Franke test data. The scores vary with polynomial degree horizontally and hyperparameter $\lambda $ vertically. In the right columns we have cropped away degrees 1 and 3 (1 and 5) and the 15 (20) largest $\lambda $ values for Ridge (Lasso), purely for visualization purposes.}}{11}{figure.caption.43}\protected@file@percent }
\newlabel{fig:MSE R2}{{6}{11}{MSE (upper rows) and $R^2$ (lower rows) for Ridge (top section) and Lasso (bottom section) regression evaluated on the Franke test data. The scores vary with polynomial degree horizontally and hyperparameter $\lambda $ vertically. In the right columns we have cropped away degrees 1 and 3 (1 and 5) and the 15 (20) largest $\lambda $ values for Ridge (Lasso), purely for visualization purposes}{figure.caption.43}{}}
\newlabel{fig:MSE R2@cref}{{[figure][6][]6}{[1][10][]11}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces MSE evaluated on the Franke function training set (blue) and test set (red) for 21 evenly spaced polynomial degrees in the interval $[1, 81]$.}}{12}{figure.caption.46}\protected@file@percent }
\newlabel{fig:e train test}{{7}{12}{MSE evaluated on the Franke function training set (blue) and test set (red) for 21 evenly spaced polynomial degrees in the interval $[1, 81]$}{figure.caption.46}{}}
\newlabel{fig:e train test@cref}{{[figure][7][]7}{[1][10][]12}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2}Parameter Dependencies of MSE, Bias and Variance}{12}{section*.47}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {D}Resampling Methods}{12}{section*.49}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1}OLS: Cross-Validation VS Bootstrap}{12}{section*.50}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces MSE (orange), bias (blue) and variance (pink) for OLS regression evaluated on Franke test data and plotted as functions of polynomial degree (upper left), number of data points (upper right), number of bootstrap steps (lower left) and test size fraction (lower right). When these are not varied we have used degree 5, $50\times 50$ data points, 100 bootstrap steps and a test size fraction of 0.2. Note that some axes are scaled logarithmically and some have a linear scale.}}{13}{figure.caption.48}\protected@file@percent }
\newlabel{fig:e bias variance}{{8}{13}{MSE (orange), bias (blue) and variance (pink) for OLS regression evaluated on Franke test data and plotted as functions of polynomial degree (upper left), number of data points (upper right), number of bootstrap steps (lower left) and test size fraction (lower right). When these are not varied we have used degree 5, $50\times 50$ data points, 100 bootstrap steps and a test size fraction of 0.2. Note that some axes are scaled logarithmically and some have a linear scale}{figure.caption.48}{}}
\newlabel{fig:e bias variance@cref}{{[figure][8][]8}{[1][12][]13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2}Cross-Validation With Ridge and Lasso}{13}{section*.52}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces MSE evaluated on Franke (upper row) and cosmological (lower row) test data as function of polynomial degrees in the intervals $[1,15]$ (Franke) and $[1, 31]$ (cosmological) and number of folds $k\in [5, 15]$ used in cross-validation (contour plots on the left). On the right we have plotted the MSE's purely as functions of complexity when using the bootstrap resampling method with 100 steps.}}{14}{figure.caption.51}\protected@file@percent }
\newlabel{fig:kfold vs bootstrap}{{9}{14}{MSE evaluated on Franke (upper row) and cosmological (lower row) test data as function of polynomial degrees in the intervals $[1,15]$ (Franke) and $[1, 31]$ (cosmological) and number of folds $k\in [5, 15]$ used in cross-validation (contour plots on the left). On the right we have plotted the MSE's purely as functions of complexity when using the bootstrap resampling method with 100 steps}{figure.caption.51}{}}
\newlabel{fig:kfold vs bootstrap@cref}{{[figure][9][]9}{[1][13][]14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E}Fits to the Cosmological Data}{14}{section*.54}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1}Complexity Dependency in OLS}{14}{section*.55}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces MSE evaluated on the Franke (top section) and cosmological (bottom section) test sets as function of polynomial degrees and number of $k$-folds used in cross-validation, for Ridge (upper rows) and Lasso (lower rows) regression. We have used $\lambda =0.001$ and $\lambda =0.5$ in the left and right columns, respectively.}}{15}{figure.caption.53}\protected@file@percent }
\newlabel{fig:kfold Ridge Lasso}{{10}{15}{MSE evaluated on the Franke (top section) and cosmological (bottom section) test sets as function of polynomial degrees and number of $k$-folds used in cross-validation, for Ridge (upper rows) and Lasso (lower rows) regression. We have used $\lambda =0.001$ and $\lambda =0.5$ in the left and right columns, respectively}{figure.caption.53}{}}
\newlabel{fig:kfold Ridge Lasso@cref}{{[figure][10][]10}{[1][14][]15}}
\bibdata{Project_1Notes,references}
\bibcite{gasoline}{{1}{2024}{{James W.~Wadsley}}{{}}}
\bibcite{notes}{{2}{2021}{{Hjorth-Jensen}}{{}}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2}Comparing Regression Variants}{16}{section*.57}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusion}{16}{section*.59}\protected@file@percent }
\newlabel{sec:conclusion}{{V}{16}{}{section*.59}{}}
\newlabel{sec:conclusion@cref}{{[section][5][]V}{[1][16][]16}}
\@writefile{toc}{\contentsline {section}{\numberline {}References}{16}{section*.60}\protected@file@percent }
\bibcite{music}{{3}{2024}{{Hahn}}{{}}}
\bibcite{scikit-learn}{{4}{2011}{{Pedregosa\ \emph  {et~al.}}}{{Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos, Cournapeau, Brucher, Perrot,\ and\ Duchesnay}}}
\bibcite{ESL}{{5}{2009}{{Hastie\ \emph  {et~al.}}}{{Hastie, Tibshirani,\ and\ Friedman}}}
\bibcite{Python}{{6}{2023}{{{Python Software Foundation}}}{{}}}
\bibcite{Numpy}{{7}{2023}{{{NumPy Developers}}}{{}}}
\bibcite{Matplotlib}{{8}{2023}{{{Matplotlib Development Team}}}{{}}}
\bibcite{VSCode}{{9}{2023{}}{{Microsoft}}{{}}}
\bibcite{Copilot}{{10}{2023{}}{{Microsoft}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Contour plots of the cosmological simulation data (upper left) and the OLS fits for polynomial degrees 5 (upper right), 10 (middle left), 20 (middle right), 30 (lower left) and 50 (lower right).}}{17}{figure.caption.56}\protected@file@percent }
\newlabel{fig:density complexity}{{11}{17}{Contour plots of the cosmological simulation data (upper left) and the OLS fits for polynomial degrees 5 (upper right), 10 (middle left), 20 (middle right), 30 (lower left) and 50 (lower right)}{figure.caption.56}{}}
\newlabel{fig:density complexity@cref}{{[figure][11][]11}{[1][16][]17}}
\bibcite{Git}{{11}{2023}{{Hamano}}{{}}}
\bibcite{GitHub}{{12}{2023{}}{{Microsoft}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Contour plots of the cosmological simulation data (upper left) and OLS (upper right), Ridge (lower left) and Lasso (lower right) regression fits using polynomial degree 30, $\lambda =0.001$ for both Ridge and Lasso, and $k=5$ folds in cross-validation.}}{18}{figure.caption.58}\protected@file@percent }
\newlabel{fig:density OLS Ridge Lasso}{{12}{18}{Contour plots of the cosmological simulation data (upper left) and OLS (upper right), Ridge (lower left) and Lasso (lower right) regression fits using polynomial degree 30, $\lambda =0.001$ for both Ridge and Lasso, and $k=5$ folds in cross-validation}{figure.caption.58}{}}
\newlabel{fig:density OLS Ridge Lasso@cref}{{[figure][12][]12}{[1][16][]18}}
\newlabel{LastBibItem}{{12}{18}{}{section*.60}{}}
\newlabel{LastBibItem@cref}{{[section][5][]V}{[1][18][]18}}
\@writefile{toc}{\appendix }
\@writefile{toc}{\contentsline {section}{\numberline {A}Code}{19}{section*.61}\protected@file@percent }
\newlabel{appsec:code}{{A}{19}{}{section*.61}{}}
\newlabel{appsec:code@cref}{{[appendix][1][2147483647]A}{[1][19][]19}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Derivations}{19}{section*.62}\protected@file@percent }
\newlabel{appsec:derivations}{{B}{19}{}{section*.62}{}}
\newlabel{appsec:derivations@cref}{{[appendix][2][2147483647]B}{[1][19][]19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1}Expectation value and variance of the OLS estimator $\boldsymbol  {\hat  {\beta }}$}{19}{section*.63}\protected@file@percent }
\newlabel{subapp:beta OLS}{{B\,1}{19}{}{section*.63}{}}
\newlabel{subapp:beta OLS@cref}{{[subappendix][1][2147483647,2]B\,1}{[1][19][]19}}
\newlabel{appeq:expect beta OLS}{{{B5}}{19}{}{AMS.65}{}}
\newlabel{appeq:expect beta OLS@cref}{{[equation][2147483647][]{B5}}{[1][19][]19}}
\bibstyle{apsrev4-1}
\citation{REVTEX41Control}
\citation{apsrev41Control}
\newlabel{appeq:var beta OLS}{{{B6}}{20}{}{AMS.67}{}}
\newlabel{appeq:var beta OLS@cref}{{[equation][2147483647][]{B6}}{[1][19][]20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2}MSE expressed in terms of model bias, model variance and noise variance}{20}{section*.68}\protected@file@percent }
\newlabel{subapp:cost}{{B\,2}{20}{}{section*.68}{}}
\newlabel{subapp:cost@cref}{{[subappendix][2][2147483647,2]B\,2}{[1][20][]20}}
\newlabel{appeq:cost OLS}{{{B7}}{20}{}{AMS.70}{}}
\newlabel{appeq:cost OLS@cref}{{[equation][2147483647][]{B7}}{[1][20][]20}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Additional Figures}{21}{section*.72}\protected@file@percent }
\newlabel{appsec:figures}{{C}{21}{}{section*.72}{}}
\newlabel{appsec:figures@cref}{{[appendix][3][2147483647]C}{[1][20][]21}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces MSE (upper rows) and $R^2$ (lower rows) for Ridge (top section) and Lasso (bottom section) regression evaluated on the cosmological test set. The scores vary with polynomial degree horizontally and hyperparameter $\lambda $ vertically. In the right columns we have cropped away degrees smaller than 19, as well as the 3 largest $\lambda $'s only for Lasso, purely for visualization purposes.}}{21}{figure.caption.71}\protected@file@percent }
\newlabel{appfig:g MSE R2}{{13}{21}{MSE (upper rows) and $R^2$ (lower rows) for Ridge (top section) and Lasso (bottom section) regression evaluated on the cosmological test set. The scores vary with polynomial degree horizontally and hyperparameter $\lambda $ vertically. In the right columns we have cropped away degrees smaller than 19, as well as the 3 largest $\lambda $'s only for Lasso, purely for visualization purposes}{figure.caption.71}{}}
\newlabel{appfig:g MSE R2@cref}{{[figure][13][2147483647]13}{[1][20][]21}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Surface plots of the cosmological simulation data (left) and the OLS fit for polynomial degree 30 (right).}}{22}{figure.caption.73}\protected@file@percent }
\newlabel{appfig:density surf}{{14}{22}{Surface plots of the cosmological simulation data (left) and the OLS fit for polynomial degree 30 (right)}{figure.caption.73}{}}
\newlabel{appfig:density surf@cref}{{[figure][14][2147483647]14}{[1][20][]22}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Contour plots of the cosmological simulation data (upper left) and the OLS fits for the entire data (upper right), 4 separate pieces stitched back together (lower left) and 100 separate pieces stitched back together (lower right). We have used a polynomial degree of 30 for all fits.}}{22}{figure.caption.74}\protected@file@percent }
\newlabel{appfig:density pieces}{{15}{22}{Contour plots of the cosmological simulation data (upper left) and the OLS fits for the entire data (upper right), 4 separate pieces stitched back together (lower left) and 100 separate pieces stitched back together (lower right). We have used a polynomial degree of 30 for all fits}{figure.caption.74}{}}
\newlabel{appfig:density pieces@cref}{{[figure][15][2147483647]15}{[1][20][]22}}
\newlabel{LastPage}{{}{22}{}{}{}}
\gdef \@abspage@last{22}
