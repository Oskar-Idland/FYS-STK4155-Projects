\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{gasoline}
\newlabel{FirstPage}{{}{1}{}{section*.1}{}}
\newlabel{FirstPage@cref}{{}{[1][1][]1}}
\@writefile{toc}{\contentsline {title}{\begin{Large}Project 1\end{Large}\\\vspace  {5pt}FYS-STK4155}{1}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {abstract}{Abstract}{1}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section*.3}\protected@file@percent }
\newlabel{sec:introduction}{{I}{1}{}{section*.3}{}}
\newlabel{sec:introduction@cref}{{[section][1][]I}{[1][1][]1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Theory}{1}{section*.4}\protected@file@percent }
\newlabel{sec:theory}{{II}{1}{}{section*.4}{}}
\newlabel{sec:theory@cref}{{[section][2][]II}{[1][1][]1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Regression Analysis}{1}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1}Ordinary Least Squares}{2}{section*.6}\protected@file@percent }
\newlabel{subsubsec:ols}{{II\,A\,1}{2}{}{section*.6}{}}
\newlabel{subsubsec:ols@cref}{{[subsubsection][1][2,1]II\,A\,1}{[1][2][]2}}
\newlabel{eq:OLS cost}{{5}{2}{}{equation.2.5}{}}
\newlabel{eq:OLS cost@cref}{{[equation][5][]5}{[1][2][]2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2}Ridge}{2}{section*.7}\protected@file@percent }
\newlabel{subsubsec:ridge}{{II\,A\,2}{2}{}{section*.7}{}}
\newlabel{subsubsec:ridge@cref}{{[subsubsection][2][2,1]II\,A\,2}{[1][2][]2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3}Lasso}{3}{section*.8}\protected@file@percent }
\newlabel{subsubsec:lasso}{{II\,A\,3}{3}{}{section*.8}{}}
\newlabel{subsubsec:lasso@cref}{{[subsubsection][3][2,1]II\,A\,3}{[1][3][]3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B}Properties of Predictive Models}{3}{section*.9}\protected@file@percent }
\newlabel{subsec:tradeoff}{{II\,B}{3}{}{section*.9}{}}
\newlabel{subsec:tradeoff@cref}{{[subsection][2][2]II\,B}{[1][3][]3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1}Predicted Values}{3}{section*.10}\protected@file@percent }
\newlabel{eq:Bias}{{16}{3}{}{equation.2.16}{}}
\newlabel{eq:Bias@cref}{{[equation][16][]16}{[1][3][]3}}
\newlabel{eq:Var}{{17}{3}{}{equation.2.17}{}}
\newlabel{eq:Var@cref}{{[equation][17][]17}{[1][3][]3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2}Model Bias}{3}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3}Model Variance}{3}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4}Bias-Variance Tradeoff}{4}{section*.13}\protected@file@percent }
\newlabel{eq:model error}{{20}{4}{}{equation.2.20}{}}
\newlabel{eq:model error@cref}{{[equation][20][]20}{[1][4][]4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C}Resampling Methods}{4}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1}Bootstrap}{4}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2}Cross-Validation}{4}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {D}The Franke Function}{4}{section*.17}\protected@file@percent }
\newlabel{subsec:franke}{{II\,D}{4}{}{section*.17}{}}
\newlabel{subsec:franke@cref}{{[subsection][4][2]II\,D}{[1][4][]4}}
\citation{gasoline}
\citation{music}
\newlabel{eq:Franke}{{{21}}{5}{}{AMS.19}{}}
\newlabel{eq:Franke@cref}{{[equation][2147483647][]{21}}{[1][4][]5}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Visualization of the two-dimensional Franke function expressed in \eqref  {eq:Franke}.}}{5}{figure.caption.20}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:Franke}{{1}{5}{Visualization of the two-dimensional Franke function expressed in \eqref {eq:Franke}}{figure.caption.20}{}}
\newlabel{fig:Franke@cref}{{[figure][1][]1}{[1][5][]5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E}Cosmological Simulation Data}{5}{section*.21}\protected@file@percent }
\newlabel{subsec:simulation}{{II\,E}{5}{}{section*.21}{}}
\newlabel{subsec:simulation@cref}{{[subsection][5][2]II\,E}{[1][5][]5}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Methods \& Implementation}{5}{section*.23}\protected@file@percent }
\newlabel{sec:methods}{{III}{5}{}{section*.23}{}}
\newlabel{sec:methods@cref}{{[section][3][]III}{[1][5][]5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Regression Analysis}{5}{section*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1}Creating the Design Matrix}{5}{section*.25}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2}Generating the data}{5}{section*.26}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Logarithm of dark matter density in the simulation box averaged over one of the three axes at redshift $z\approx 12.88$. Plotted as contour plot on the left and as surface plot on the right.}}{6}{figure.caption.22}\protected@file@percent }
\newlabel{fig:density}{{2}{6}{Logarithm of dark matter density in the simulation box averaged over one of the three axes at redshift $z\approx 12.88$. Plotted as contour plot on the left and as surface plot on the right}{figure.caption.22}{}}
\newlabel{fig:density@cref}{{[figure][2][]2}{[1][5][]6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3}Preprocessing}{6}{section*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4}Parameter Dependencies}{6}{section*.28}\protected@file@percent }
\bibdata{Project_1Notes,references}
\bibcite{gasoline}{{1}{2024}{{James W.~Wadsley}}{{}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B}Bias-Variance Tradeoff}{7}{section*.29}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Fig. 2.11 of Hastie, Tibshirani, and Friedman illustrating bias-variance trade-off as a function of model complexity \colorbox {magenta}{cite}}}{7}{figure.caption.30}\protected@file@percent }
\newlabel{fig:Hastie}{{3}{7}{Fig. 2.11 of Hastie, Tibshirani, and Friedman illustrating bias-variance trade-off as a function of model complexity \colorbox {magenta}{cite}}{figure.caption.30}{}}
\newlabel{fig:Hastie@cref}{{[figure][3][]3}{[1][7][]7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1}Bootstrap With OLS}{7}{section*.31}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2}Cross-Validation}{7}{section*.32}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {C}The Program}{7}{section*.33}\protected@file@percent }
\newlabel{subsec:program}{{III\,C}{7}{}{section*.33}{}}
\newlabel{subsec:program@cref}{{[subsection][3][3]III\,C}{[1][7][]7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1}Code Structure}{7}{section*.34}\protected@file@percent }
\newlabel{subsubsec:codestructure}{{III\,C\,1}{7}{}{section*.34}{}}
\newlabel{subsubsec:codestructure@cref}{{[subsubsection][1][3,3]III\,C\,1}{[1][7][]7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2}Tools}{7}{section*.35}\protected@file@percent }
\newlabel{subsubsec:tools}{{III\,C\,2}{7}{}{section*.35}{}}
\newlabel{subsubsec:tools@cref}{{[subsubsection][2][3,3]III\,C\,2}{[1][7][]7}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Results \& Discussion}{7}{section*.36}\protected@file@percent }
\newlabel{sec:results discussion}{{IV}{7}{}{section*.36}{}}
\newlabel{sec:results discussion@cref}{{[section][4][]IV}{[1][7][]7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Effects of Data Scaling}{7}{section*.37}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {B}Hyperparameter in Ridge and Lasso}{7}{section*.42}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusion}{7}{section*.55}\protected@file@percent }
\newlabel{sec:conclusion}{{V}{7}{}{section*.55}{}}
\newlabel{sec:conclusion@cref}{{[section][5][]V}{[1][7][]7}}
\bibcite{music}{{2}{2024}{{Hahn}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces MSE (upper row) and $R^2$ (lower row) evaluated on the Franke function test set using unscaled (left column) and scaled (right column) values, for polynomial degrees in the interval $[1,6]$.}}{8}{figure.caption.38}\protected@file@percent }
\newlabel{fig:a error scaled vs raw}{{4}{8}{MSE (upper row) and $R^2$ (lower row) evaluated on the Franke function test set using unscaled (left column) and scaled (right column) values, for polynomial degrees in the interval $[1,6]$}{figure.caption.38}{}}
\newlabel{fig:a error scaled vs raw@cref}{{[figure][4][]4}{[1][7][]8}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The coefficients $\beta $ for the Franke function fit estimated using unscaled (blue) and scaled (red) data, plotted for polynomial degrees in the interval $[1,6]$.}}{8}{figure.caption.39}\protected@file@percent }
\newlabel{fig:a beta scaled vs raw}{{5}{8}{The coefficients $\beta $ for the Franke function fit estimated using unscaled (blue) and scaled (red) data, plotted for polynomial degrees in the interval $[1,6]$}{figure.caption.39}{}}
\newlabel{fig:a beta scaled vs raw@cref}{{[figure][5][]5}{[1][7][]8}}
\@writefile{toc}{\contentsline {section}{\numberline {}References}{8}{section*.56}\protected@file@percent }
\newlabel{LastBibItem}{{2}{8}{}{section*.56}{}}
\newlabel{LastBibItem@cref}{{[section][5][]V}{[1][8][]8}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces MSE (upper row) and $R^2$ (lower row) evaluated on the cosmological test set using unscaled (left column) and scaled (right column) values, for polynomial degrees in the interval $[1,41]$.}}{9}{figure.caption.40}\protected@file@percent }
\newlabel{fig:g error scaled vs raw}{{6}{9}{MSE (upper row) and $R^2$ (lower row) evaluated on the cosmological test set using unscaled (left column) and scaled (right column) values, for polynomial degrees in the interval $[1,41]$}{figure.caption.40}{}}
\newlabel{fig:g error scaled vs raw@cref}{{[figure][6][]6}{[1][7][]9}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The coefficients $\beta $ for the cosmological fit estimated using unscaled (purple) and scaled (orange) data, plotted for polynomial degrees in the interval $[1,41]$.}}{9}{figure.caption.41}\protected@file@percent }
\newlabel{fig:g beta scaled vs raw}{{7}{9}{The coefficients $\beta $ for the cosmological fit estimated using unscaled (purple) and scaled (orange) data, plotted for polynomial degrees in the interval $[1,41]$}{figure.caption.41}{}}
\newlabel{fig:g beta scaled vs raw@cref}{{[figure][7][]7}{[1][7][]9}}
\@writefile{toc}{\appendix }
\@writefile{toc}{\contentsline {section}{\numberline {A}Derivations}{9}{section*.57}\protected@file@percent }
\newlabel{appsec:derivations}{{A}{9}{}{section*.57}{}}
\newlabel{appsec:derivations@cref}{{[appendix][1][2147483647]A}{[1][9][]9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1}Expectation value and variance of the OLS estimator $\boldsymbol  {\hat  {\beta }}$}{9}{section*.58}\protected@file@percent }
\newlabel{subapp:beta OLS}{{A\,1}{9}{}{section*.58}{}}
\newlabel{subapp:beta OLS@cref}{{[subappendix][1][2147483647,1]A\,1}{[1][9][]9}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces MSE evaluated on the Franke function training set (blue) and test set (red) for 21 evenly spaced polynomial degrees in the interval $[1, 81]$.}}{10}{figure.caption.43}\protected@file@percent }
\newlabel{fig:e train test}{{8}{10}{MSE evaluated on the Franke function training set (blue) and test set (red) for 21 evenly spaced polynomial degrees in the interval $[1, 81]$}{figure.caption.43}{}}
\newlabel{fig:e train test@cref}{{[figure][8][]8}{[1][7][]10}}
\newlabel{appeq:expect beta OLS}{{{A5}}{10}{}{AMS.60}{}}
\newlabel{appeq:expect beta OLS@cref}{{[equation][2147483647][]{A5}}{[1][10][]10}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces MSE (upper row) and $R^2$ (lower row) for Ridge regression evaluated on the Franke test data and contour plotted as functions of polynomial degree (horizontal axes) and hyperparameter $\lambda $ (vertical axes). We have used 21 evenly spaced degrees in the interval $[1, 41]$ and 30 logarithmically spaced values for $\lambda $ in the interval $[10^{-5},10^{-1}]$. We have cropped away degrees 1 and 3 and the 15 largest $\lambda $ values purely for visualization purposes.}}{11}{figure.caption.44}\protected@file@percent }
\newlabel{fig:b MSE R2}{{9}{11}{MSE (upper row) and $R^2$ (lower row) for Ridge regression evaluated on the Franke test data and contour plotted as functions of polynomial degree (horizontal axes) and hyperparameter $\lambda $ (vertical axes). We have used 21 evenly spaced degrees in the interval $[1, 41]$ and 30 logarithmically spaced values for $\lambda $ in the interval $[10^{-5},10^{-1}]$. We have cropped away degrees 1 and 3 and the 15 largest $\lambda $ values purely for visualization purposes}{figure.caption.44}{}}
\newlabel{fig:b MSE R2@cref}{{[figure][9][]9}{[1][7][]11}}
\newlabel{appeq:var beta OLS}{{{A6}}{11}{}{AMS.62}{}}
\newlabel{appeq:var beta OLS@cref}{{[equation][2147483647][]{A6}}{[1][10][]11}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces MSE (upper row) and $R^2$ (lower row) for Lasso regression evaluated on the Franke test data and contour plotted as functions of polynomial degree (horizontal axes) and hyperparameter $\lambda $ (vertical axes). We have used 11 evenly spaced degrees in the interval $[1, 41]$ and 30 logarithmically spaced values for $\lambda $ in the interval $[10^{-5},10^{-1}]$, but in the right column we have cropped away degrees 1 and 5 and the 20 largest $\lambda $ values.}}{12}{figure.caption.45}\protected@file@percent }
\newlabel{fig:c MSE R2}{{10}{12}{MSE (upper row) and $R^2$ (lower row) for Lasso regression evaluated on the Franke test data and contour plotted as functions of polynomial degree (horizontal axes) and hyperparameter $\lambda $ (vertical axes). We have used 11 evenly spaced degrees in the interval $[1, 41]$ and 30 logarithmically spaced values for $\lambda $ in the interval $[10^{-5},10^{-1}]$, but in the right column we have cropped away degrees 1 and 5 and the 20 largest $\lambda $ values}{figure.caption.45}{}}
\newlabel{fig:c MSE R2@cref}{{[figure][10][]10}{[1][7][]12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2}MSE expressed in terms of model bias, model variance and noise variance}{12}{section*.63}\protected@file@percent }
\newlabel{subapp:cost}{{A\,2}{12}{}{section*.63}{}}
\newlabel{subapp:cost@cref}{{[subappendix][2][2147483647,1]A\,2}{[1][11][]12}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces MSE (orange), bias (blue) and variance (pink) for OLS regression evaluated on Franke test dta and plotted as functions of polynomial degree (upper left), number of data points (upper right), number of bootstrap steps (lower left) and test size fraction (lower right). When these are not varied we have used degree 5, 50 data points in one direction (i.e. $2\:500$ in the grid), 100 bootstrap steps and a test size fraction of 0.2. Note that some axes are scaled logarithmically and some have a linear scale.}}{13}{figure.caption.46}\protected@file@percent }
\newlabel{fig:e bias variance}{{11}{13}{MSE (orange), bias (blue) and variance (pink) for OLS regression evaluated on Franke test dta and plotted as functions of polynomial degree (upper left), number of data points (upper right), number of bootstrap steps (lower left) and test size fraction (lower right). When these are not varied we have used degree 5, 50 data points in one direction (i.e. $2\:500$ in the grid), 100 bootstrap steps and a test size fraction of 0.2. Note that some axes are scaled logarithmically and some have a linear scale}{figure.caption.46}{}}
\newlabel{fig:e bias variance@cref}{{[figure][11][]11}{[1][7][]13}}
\bibstyle{apsrev4-1}
\citation{REVTEX41Control}
\citation{apsrev41Control}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces MSE evaluated on Franke test data as function of polynomial degrees in the interval $[1, 15]$ and number of folds $k\in [5, 15]$ used in cross-validation (contour plot on the left). On the right we have plotted the MSE purely as function of complexity when using the bootstrap resampling method with 100 steps.}}{14}{figure.caption.47}\protected@file@percent }
\newlabel{fig:f kfold vs bootstrap}{{12}{14}{MSE evaluated on Franke test data as function of polynomial degrees in the interval $[1, 15]$ and number of folds $k\in [5, 15]$ used in cross-validation (contour plot on the left). On the right we have plotted the MSE purely as function of complexity when using the bootstrap resampling method with 100 steps}{figure.caption.47}{}}
\newlabel{fig:f kfold vs bootstrap@cref}{{[figure][12][]12}{[1][7][]14}}
\newlabel{appeq:cost OLS}{{{A7}}{14}{}{AMS.65}{}}
\newlabel{appeq:cost OLS@cref}{{[equation][2147483647][]{A7}}{[1][13][]14}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Additional Figures}{14}{section*.66}\protected@file@percent }
\newlabel{appsec:figures}{{B}{14}{}{section*.66}{}}
\newlabel{appsec:figures@cref}{{[appendix][2][2147483647]B}{[1][14][]14}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces MSE evaluated on Franke test data as function of polynomial degrees in the interval $[1, 15]$ and number of folds $k\in [5, 15]$ used in cross-validation, for Ridge (upper row) and Lasso (lower row) regression. The upper left contour plot\colorbox {magenta}{update after running cross-val again}. We have used $\lambda =0.001$ and $\lambda =0.5$ in the left and right columns, respectively. \colorbox {magenta}{try using 0.001 and 5 instead?}}}{15}{figure.caption.48}\protected@file@percent }
\newlabel{fig:f Ridge Lasso}{{13}{15}{MSE evaluated on Franke test data as function of polynomial degrees in the interval $[1, 15]$ and number of folds $k\in [5, 15]$ used in cross-validation, for Ridge (upper row) and Lasso (lower row) regression. The upper left contour plot\colorbox {magenta}{update after running cross-val again}. We have used $\lambda =0.001$ and $\lambda =0.5$ in the left and right columns, respectively. \colorbox {magenta}{try using 0.001 and 5 instead?}}{figure.caption.48}{}}
\newlabel{fig:f Ridge Lasso@cref}{{[figure][13][]13}{[1][7][]15}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Contour plots of the cosmological simulation data (upper left) and the OLS fits for polynomial degrees 5 (upper right), 10 (middle left), 20 (middle right), 30 (lower left) and 50 (lower right).}}{16}{figure.caption.49}\protected@file@percent }
\newlabel{fig:density complexity}{{14}{16}{Contour plots of the cosmological simulation data (upper left) and the OLS fits for polynomial degrees 5 (upper right), 10 (middle left), 20 (middle right), 30 (lower left) and 50 (lower right)}{figure.caption.49}{}}
\newlabel{fig:density complexity@cref}{{[figure][14][]14}{[1][7][]16}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Surface plots of the cosmological simulation data (left) and the OLS fit for polynomial degree 30 (right).}}{17}{figure.caption.50}\protected@file@percent }
\newlabel{fig:density surf}{{15}{17}{Surface plots of the cosmological simulation data (left) and the OLS fit for polynomial degree 30 (right)}{figure.caption.50}{}}
\newlabel{fig:density surf@cref}{{[figure][15][]15}{[1][7][]17}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces MSE (upper row) and $R^2$ (lower row) for Ridge regression evaluated on the cosmological test data and contour plotted as functions of polynomial degree (horizontal axes) and hyperparameter $\lambda $ (vertical axes). We have used 11 evenly spaced degrees in the interval $[1, 31]$ and 11 logarithmically spaced values for $\lambda $ in the interval $[10^{-5},10^{-1}]$. In the right column we have cropped away degrees smaller than 19 purely for visualization purposes.}}{18}{figure.caption.51}\protected@file@percent }
\newlabel{fig:g MSE R2 Ridge}{{16}{18}{MSE (upper row) and $R^2$ (lower row) for Ridge regression evaluated on the cosmological test data and contour plotted as functions of polynomial degree (horizontal axes) and hyperparameter $\lambda $ (vertical axes). We have used 11 evenly spaced degrees in the interval $[1, 31]$ and 11 logarithmically spaced values for $\lambda $ in the interval $[10^{-5},10^{-1}]$. In the right column we have cropped away degrees smaller than 19 purely for visualization purposes}{figure.caption.51}{}}
\newlabel{fig:g MSE R2 Ridge@cref}{{[figure][16][]16}{[1][7][]18}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces MSE (upper row) and $R^2$ (lower row) for Lasso regression evaluated on the cosmological test data and contour plotted as functions of polynomial degree (horizontal axes) and hyperparameter $\lambda $ (vertical axes). We have used 11 evenly spaced degrees in the interval $[1, 31]$ and 11 logarithmically spaced values for $\lambda $ in the interval $[10^{-5},10^{-1}]$, but in the right column we have cropped away degrees smaller than 19 and the 3 largest $\lambda $ values.}}{19}{figure.caption.52}\protected@file@percent }
\newlabel{fig:g MSE R2 Lasso}{{17}{19}{MSE (upper row) and $R^2$ (lower row) for Lasso regression evaluated on the cosmological test data and contour plotted as functions of polynomial degree (horizontal axes) and hyperparameter $\lambda $ (vertical axes). We have used 11 evenly spaced degrees in the interval $[1, 31]$ and 11 logarithmically spaced values for $\lambda $ in the interval $[10^{-5},10^{-1}]$, but in the right column we have cropped away degrees smaller than 19 and the 3 largest $\lambda $ values}{figure.caption.52}{}}
\newlabel{fig:g MSE R2 Lasso@cref}{{[figure][17][]17}{[1][7][]19}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces MSE evaluated on cosmological test data as function of polynomial degrees in the interval $[1, 31]$ and number of folds $k\in [5, 15]$ used in cross-validation (contour plot on the left). On the right we have plotted the MSE purely as function of complexity when using the bootstrap resampling method with 100 steps.}}{20}{figure.caption.53}\protected@file@percent }
\newlabel{fig:g kfold vs bootstrap}{{18}{20}{MSE evaluated on cosmological test data as function of polynomial degrees in the interval $[1, 31]$ and number of folds $k\in [5, 15]$ used in cross-validation (contour plot on the left). On the right we have plotted the MSE purely as function of complexity when using the bootstrap resampling method with 100 steps}{figure.caption.53}{}}
\newlabel{fig:g kfold vs bootstrap@cref}{{[figure][18][]18}{[1][7][]20}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces MSE evaluated on cosmological test data as function of polynomial degrees in the interval $[1, 31]$ and number of folds $k\in [5, 15]$ used in cross-validation, for Ridge (upper row) and Lasso (lower row) regression. The upper left contour plot\colorbox {magenta}{update after running cross-val again}. We have used $\lambda =0.001$ and $\lambda =0.5$ in the left and right columns, respectively. \colorbox {magenta}{try using 0.001 and 5 instead?}}}{21}{figure.caption.54}\protected@file@percent }
\newlabel{fig:g Ridge Lasso}{{19}{21}{MSE evaluated on cosmological test data as function of polynomial degrees in the interval $[1, 31]$ and number of folds $k\in [5, 15]$ used in cross-validation, for Ridge (upper row) and Lasso (lower row) regression. The upper left contour plot\colorbox {magenta}{update after running cross-val again}. We have used $\lambda =0.001$ and $\lambda =0.5$ in the left and right columns, respectively. \colorbox {magenta}{try using 0.001 and 5 instead?}}{figure.caption.54}{}}
\newlabel{fig:g Ridge Lasso@cref}{{[figure][19][]19}{[1][7][]21}}
\newlabel{LastPage}{{}{21}{}{}{}}
\gdef \@abspage@last{21}
