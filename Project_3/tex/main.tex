\PassOptionsToPackage{square,comma,numbers,sort&compress,super}{natbib}
\documentclass[aps,pra,english,notitlepage,reprint,nofootinbib]{revtex4-1}  % defines the basic parameters of the document
% For preview: skriv i terminal: latexmk -pdf -pvc filnavn
% If you want a single-column, remove "reprint"

% Allows special characters (including æøå)
% \usepackage[mathletters]{ucs}
% \usepackage[utf8x]{inputenc}
% \usepackage[english]{babel}
\usepackage{silence}
\WarningFilter{revtex4-1}{Repair the float}
% \usepackage[mathletters]{ucs}
% \usepackage[utf8x]{inputenc}
%% Note that you may need to download some of these packages manually, it depends on your setup.
%% I recommend downloading TeXMaker, because it includes a large library of the most common packages.

\usepackage{physics,amssymb}  % mathematical symbols (physics imports amsmath)
\usepackage{amsmath}
\usepackage{graphicx}
% include graphics such as plots
\usepackage[dvipsnames]{xcolor}           % set colors
% \usepackage{hyperref}         % automagic cross-referencing
%\usepackage{url}
% \usepackage{cleveref}
\usepackage{listings}         % display code
\usepackage{subfigure}        % imports a lot of cool and useful figure commands
\usepackage{subcaption}
%\usepackage{float}
%\usepackage[section]{placeins}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{cprotect}
\usepackage{multirow}
\usepackage{array, booktabs}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\usepackage[noend]{algpseudocode}
\usepackage{subfigure}
\newcommand{\imp}{\hspace{5pt}\Rightarrow\hspace{5pt}}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\usepackage{tikz}
\usepackage{hyperref}         % automagic cross-referencing
\usepackage{cleveref}
\usepackage{comment}
% defines the color of hyperref objects
% Blending two colors:  blue!80!black  =  80% blue and 20% black
\hypersetup{ % this is just my personal choice, feel free to change things
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black},
breaklinks=true}
\urlstyle{same}

\renewcommand{\bibsection}{
\section*{References}}
\newcommand{\psp}{\hspace{1pt}}
% ===========================================

\begin{document}

\title{\texorpdfstring{
        \begin{Large}Project 2
\end{Large}\\\vspace{5pt}FYS-STK4155}{Lg}}
\author{Krithika Gunesegaran, Oskar Idland, Erik Røset \& Arangan Subramaniam}
\date{\today}
\affiliation{University of Oslo, Department of Physics}

\begin{abstract}
    \centering
The rapid growth of artificial intelligence (AI) and machine learning has significantly impacted medical imaging, particularly in tasks such as tumor detection and disease classification. However, deploying deep learning models like Convolutional Neural Networks (CNNs) in environments with limited resources remains a challenge. To address this issue, efficient architectures like MobileNet and ResNet have been developed. MobileNet is designed for computational efficiency, making it suitable for mobile medical applications, while ResNet, with its residual connections, tackles the degradation problem in deeper networks. This study compares the performance of three neural network architectures: custom CNN, MobileNet, and ResNet101 on a breast cancer histopathological dataset. We aim to evaluate how these models perform on a small, imbalanced dataset, focusing on their accuracy and efficiency in a medical context. Our results show that ResNet101, significantly outperforms the other models, achieving higher F1-scores (0.87) and more balanced class performance. In contrast, while MobileNet demonstrated high precision for certain classes, it struggled with recall due to class imbalance. The findings suggest that ResNet101’s superior performance makes it more suitable for complex medical image classification tasks, particularly when higher accuracy and balanced class performance are essential. This study highlights the balance between model complexity, data limitations, and computational constraints in creating practical medical AI systems.
 %   \colorbox{magenta}{Add abstract here}
\end{abstract}
\maketitle
\onecolumngrid
\begin{center}
    \vspace{-15pt}
    % LINK TO REPOSITORY
    \href{https://github.com/Oskar-Idland/FYS-STK4155-Projects}{https://github.com/Oskar-Idland/FYS-STK4155-Projects}%{GitHub Repository}
    \vspace{5pt}
\end{center}
\twocolumngrid
% ===========================================

\section{Introduction}\label{sec:introduction}

\input{Introduction}

% ===========================================
\section{Theory}\label{sec:theory}
\input{Theory}

\section{Methods \& Implementation}\label{sec:methods}
\input{Methods}

\section{Results \& Discussion}\label{sec:results discussion}
\include{Results}

\section{Conclusion}\label{sec:conclusion}

These experimental results yield several crucial insights for developing practical medical image classification systems:

\begin{itemize}
    \item \textbf{Transfer Learning Effectiveness:} Pre-trained models can significantly outperform custom architectures on small datasets,  with ResNet101 demonstrating nearly $20\%$ higher F1-scores (0.87) than models trained from scratch (CNN: 0.68, MobileNet: 0.62).
    \item \textbf{Architectural Complexity Trade-offs:} The superior performance of the Simple CNN compared to MobileNet contradicts the general assumption that more complex architectures yield better results. This finding suggests that architectural complexity must be carefully balanced against dataset size, particularly in medical imaging applications where large, annotated datasets are often unavailable.
    \item \textbf{Class Imbalance Challenges:} The degraded performance of both Simple CNN and MobileNet on minority classes, despite data augmentation efforts, highlights persistent challenges in handling class imbalance in medical datasets. ResNet101's more balanced performance suggests that transfer learning can help mitigate these issues.
    \item \textbf{Resource Considerations:} While transfer learning from large-scale pre-trained models offers superior performance, the requirements for computational resources and initial training data may limit accessibility. The adequate performance of simpler architectures suggests that targeted, dataset-appropriate model design might offer a more practical solution in resource-constrained settings.
\end{itemize}

These findings demonstrate that successful medical image classification with limited data requires careful consideration of model complexity, transfer learning opportunities, and computational constraints rather than defaulting to more complex architectures. Future work should investigate methods to improve minority class performance and explore architectural modifications that better utilize limited training data.

\Urlmuskip=0mu plus 1mu\relax
\onecolumngrid
\bibliography{references}

\newpage
% ===========================================
\appendix
\section{Code}\label{appsec:code}
Link to our GitHub repository: \href{https://github.com/Oskar-Idland/FYS-STK4155-Projects}{https://github.com/Oskar-Idland/FYS-STK4155-Projects}

\end{document}
